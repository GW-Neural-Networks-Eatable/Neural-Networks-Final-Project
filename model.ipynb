{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create label dictionary\n",
    "Since the price buckets may change, we'll create a dictionary to map the price buckets to a prettier format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25_30': '$25-$30',\n",
       " '35_40': '$35-$40',\n",
       " '10_15': '$10-$15',\n",
       " '20_25': '$20-$25',\n",
       " '45_50': '$45-$50',\n",
       " '30_35': '$30-$35',\n",
       " '15_20': '$15-$20',\n",
       " '40_45': '$40-$45'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the buckets based on sub-folders of `buckets`\n",
    "buckets = [f for f in os.listdir('buckets') if os.path.isdir(os.path.join('buckets', f))]\n",
    "\n",
    "# Create a dictionary of classes where the key is the class name and the value is a formatted string of the class name\n",
    "classes = {bucket: '$' + bucket.replace('_', '-$').title() for bucket in buckets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "We'll start by loading the data from the `buckets` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 8 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory buckets. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m price_data \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuckets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m price_data\u001b[38;5;241m.\u001b[39mcardinality()\n",
      "File \u001b[0;32m~/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/utils/image_dataset.py:303\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m image_paths, labels \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mget_training_or_validation_split(\n\u001b[1;32m    300\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[1;32m    301\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[1;32m    308\u001b[0m dataset \u001b[38;5;241m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[1;32m    309\u001b[0m     image_paths\u001b[38;5;241m=\u001b[39mimage_paths,\n\u001b[1;32m    310\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m     crop_to_aspect_ratio\u001b[38;5;241m=\u001b[39mcrop_to_aspect_ratio,\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No images found in directory buckets. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "price_data = keras.utils.image_dataset_from_directory(\"buckets\", labels=\"inferred\", image_size=(image_dim,image_dim), batch_size=None)\n",
    "price_data.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=600>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=2200>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=2800>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data.shuffle(price_data.cardinality())\n",
    "test_prices = price_data.take(1200) \n",
    "train_prices = price_data.skip(1200)\n",
    "val_prices = train_prices.skip(600)\n",
    "test_prices = test_prices.take(600)\n",
    "\n",
    "test_prices.cardinality(), val_prices.cardinality(), train_prices.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape images (not necessary with this dataset, but you might enjoy this code for the future)\n",
    "size = (image_dim, image_dim)\n",
    "train_ds = train_prices.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "validation_ds = val_prices.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "test_ds = test_prices.map(lambda x, y: (tf.image.resize(x, size), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll also setup prefetching so that we can more easily load the data for training/testing\n",
    "batch_size = 16\n",
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "In the first line we'll load the Xception model trained on Imagenet data. However we'll explicity drop the fully connected layers so we can add our own (seen in the `include_top=False` line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 80, 80, 3)]       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 80, 80, 3)         0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 3, 3, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20863529 (79.59 MB)\n",
      "Trainable params: 2049 (8.00 KB)\n",
      "Non-trainable params: 20861480 (79.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 80, 80, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>,\n",
       " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 80, 80, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Keras we load the Xception model\n",
    "base_model = keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # load the model with weights from training on ImageNet\n",
    "    input_shape=(80, 80, 3), \n",
    "    include_top=False, # This states we won't include the \"top\" layers (the classifier)\n",
    ")\n",
    "\n",
    "# We can freeze the weights of any model/layer so they won't be updated when training the model\n",
    "base_model.trainable = False\n",
    "\n",
    "# With the base model defined we can create a regular Keras sequential model\n",
    "inputs = keras.Input(shape=(80, 80, 3))\n",
    "# This version of the Xception model expects inputs to be scaled from (0, 255) to a range of (-1., +1.)\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "# The base model contains batchnorm layers, by setting training=False here it'll prevent those from being modified\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n",
    "train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 80, 80, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[1;32m      3\u001b[0m     loss\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy()],\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/l4/p__14z5x5rl4rjxvfwyqm1z00000gn/T/__autograph_generated_filebewxwu55.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 80, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 1\n",
    "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
      "<class 'tensorflow.python.data.ops.take_op._TakeDataset'>\n",
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 80, 80, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 80, 80, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 10\u001b[0m     model_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     model_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(model_preds\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/l4/p__14z5x5rl4rjxvfwyqm1z00000gn/T/__autograph_generated_filekam4gvjz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ozzysimpson/anaconda3/envs/Neural/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 80, 80, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(type(test_ds))\n",
    "print(type(test_ds.take(1)))\n",
    "print(test_ds)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for ix, (images, labels) in enumerate(train_ds.take(1)):\n",
    "    model_preds = model.predict(images)\n",
    "    model_labels = np.where(model_preds>0, 1, 0)\n",
    "    for iy in range(9):\n",
    "        ax = plt.subplot(3, 3, iy + 1)\n",
    "        plt.imshow(np.array(images[iy]).astype(int))\n",
    "        plt.title(f\"Actual: {int(labels[iy])} - Predicted: {model_labels[iy]}\")\n",
    "        plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
