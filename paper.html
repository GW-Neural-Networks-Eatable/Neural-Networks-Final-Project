<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Talia Novack">
<meta name="author" content="Zack Rahbar">
<meta name="author" content="Lauren Schmidt">
<meta name="author" content="Ozzy Simpson">

<title>Eatable</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="paper_files/libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="paper_files/libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="paper_files/libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<style>html{ scroll-behavior: smooth; }</style>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods"><span class="header-section-number">2</span> Methods</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data"><span class="header-section-number">2.1</span> Data</a></li>
  <li><a href="#neural-network" id="toc-neural-network" class="nav-link" data-scroll-target="#neural-network"><span class="header-section-number">2.2</span> Neural Network</a></li>
  <li><a href="#measuring-success" id="toc-measuring-success" class="nav-link" data-scroll-target="#measuring-success"><span class="header-section-number">2.3</span> Measuring Success</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">3</span> Results</a></li>
  <li><a href="#future-work" id="toc-future-work" class="nav-link" data-scroll-target="#future-work"><span class="header-section-number">4</span> Future Work</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">5</span> References</a></li>
  </ul>
<div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="https://github.com/GW-Neural-Networks-Eatable/Neural-Networks-Final-Project" target="_blank"><i class="bi bi-github"></i>GitHub Repo</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Eatable</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Talia Novack <a href="mailto:talianovack@gwu.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
             <p>Zack Rahbar <a href="mailto:zackrahbar@gwu.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
             <p>Lauren Schmidt <a href="mailto:laurenschmidt@gwu.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
             <p>Ozzy Simpson <a href="mailto:ozzy@gwu.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>As college students in a major city, we often enjoy eating at restaurants as a form of social outing, but, given the budget of a college student, our first thoughts after a meal are often, “Was that food really worth that price?” or “Was that food a total bargain?” Given the opportunity to design a project of our own choosing, we set out to answer the question of, “is a meal a scam or a steal?” In the development of our model we discovered that we had also inadvertently answered a second question. We realized that our model could not only tell the consumer whether they are overspending or getting a great deal on a meal, but also tell a restauranteur whether they are underpricing their dishes and losing revenue, or overpricing dishes and losing customers, and therefore revenue.</p>
<p>While no exact prior model exists, we based our experiment on the design of two previous models published in journal articles. The first model attempted to guess the prices of secondhand clothing based on image input that was often non-standardized <span class="citation" data-cites="han">(<a href="#ref-han" role="doc-biblioref">Han et al. 2019</a>)</span>. We were tasked with learning how to account for photos taken by the average person instead of professionally staged with lighting and a backdrop, which was also addressed by the first model. The second model attempted to classify types of food from a photo, a process we believed could help us in predicting food price based on image input <span class="citation" data-cites="nordin">(<a href="#ref-nordin" role="doc-biblioref">Nordin, Xin, and Aziz 2019</a>)</span>. The model was limited as it only was able to identify different types of rice (a task too specific for our end goal), but the architecture enabled us to identify subtle differences between similar foods. Although neither of these models were identical to our proposed model, they provided unique insights about individual components that made up our project. With the help of previous literature, we gained a solid foundation for creating a unique model to solve a novel problem.</p>
</section>
<section id="methods" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="methods"><span class="header-section-number">2</span> Methods</h2>
<p>Our experiment attempts to predict the price of meals based on an input image. We began by collecting data to train our model on, and sourced meal images from restaurants on Toast. After scraping and collecting sufficient data, we constructed a Keras Xception model including weights trained on Imagenet data. With training, testing, and validation sets of data collected and established, we could begin to modify layers in the model to determine the most helpful iteration of the model. We first created a model that classified images into price “buckets,” but realized that grouping the images into $5-incremented buckets lost valuable price data. We shifted to a regression model that had better accuracy than bucketed data. Our final model includes Global Average Pooling 2D, dense ReLU-activated, and dense linear layers, as well as several hyperparameters defined by hyperparameter optimization. We measured the success of the model using mean-squared error as a loss function, and then calculated the number of correct predictions at increasing margins (from $1 to $20).</p>
<section id="data" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="data"><span class="header-section-number">2.1</span> Data</h3>
<p>In the early stages of our project, we realized there did not exist a large enough data set of food images and prices that was freely available to us. We decided to use <a href="https://www.toasttab.com/local/washington-dc-restaurants">Toast</a>, a cloud-based restaurant management software that works as the internal and external point of sale for many restaurants, as our training data source. Our decision to use Toast as the software compared to other online food ordering applications like Grubhub or Uber Eats, came from the fact that Toast reflects the actual prices of the dishes compared to the price gouging that you see from the delivery services mentioned. To store Toast’s information in an easily accessible and understandable way, we utilized a SQLite database with two tables: one for the restaurants, and the other for the restaurant items.</p>
<p>The first assumption we made was that the training data would only use D.C. restaurants. The price of a meal can vary between cities, and with a limited amount of time to scrape a very large amount of data, we resolved to focus on D.C. restaurants for the scope of this project.</p>
<p>To actually scrape the data, we used <a href="https://playwright.dev/python/">Playwright</a>, a Microsoft developed open-source library for browser testing and web scraping. By running Playwright on our personal computers, a headless Google Chrome window was opened where the restaurants were scraped and inserted into our SQLite Restaurants table. Once all the desired restaurants were stored, we scraped the menus of those restaurants, and inserted the prices, dish names, and image paths into our Dish table. (See <a href="#fig-sql" class="quarto-xref">Figure&nbsp;1</a> for full SQL diagram.)</p>
<div id="fig-sql" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sql-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<iframe width="100%" height="500px" style="box-shadow: 0 2px 8px 0 rgba(63,69,81,0.16); border-radius:15px;" allowtransparency="true" allowfullscreen="true" scrolling="no" title="Embedded DrawSQL IFrame" frameborder="0" src="https://drawsql.app/teams/lol-56/diagrams/eatable/embed">
</iframe>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sql-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: SQL diagram
</figcaption>
</figure>
</div>
<p>The next step was to store the images of the food in such a way that our model would accept as input. We downloaded the food images into a local directory by extracting Toast’s image path from our database, replacing the internet-facing path with the local path. With this separation of actual picture files, we created a direct way for our model to access the pictures locally instead of including image downloading in the actual model.</p>
<p>To clean up our data we made the assumption of focusing solely on entrees for our model, and eliminating side dishes and drinks. Because of this, we limited training prices to be within the range of $10–$50 dishes. This also eliminated apparel items sold by some restaurants such as hats and t-shirts. A few prices that we collected also included characters such as “+”, meaning that a dish starts at a price and can increase from there. Those food items were removed from the test data set entirely.</p>
</section>
<section id="neural-network" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="neural-network"><span class="header-section-number">2.2</span> Neural Network</h3>
<p>We used the Keras Xception model with weights trained on Imagenet data, and modified the model to add our own layers. We added a Global Average Pooling 2D layer, then a dropout layer. After the initial dropout, we included a dense ReLU activated layer, and another dropout. We then used hyperparameter search to identify the optimal hyperparameters for the model. Our hyperparameter search returned a few useful specifications, including a learning rate of 0.01 and 15 epochs. We also used Hyperband to minimize loss. With a complete Xception model and hyperparameters, we could then begin to train the model.</p>
<div id="fig-model" class="lightbox quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="static/model_diagram.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1"><img src="static/model_diagram.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Model diagram
</figcaption>
</figure>
</div>
</section>
<section id="measuring-success" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="measuring-success"><span class="header-section-number">2.3</span> Measuring Success</h3>
<p>In our regression model, we quantified loss using mean squared error. Once the hyperparameters were selected and the model was trained, we evaluated the model again using mean squared error on test data as a simple measure of success. As part of this, we also inspected a small sample of the test data and the model’s prediction (<a href="#fig-test" class="quarto-xref">Figure&nbsp;3</a>).</p>
<div id="fig-test" class="lightbox quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="static/model_test.png" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2"><img src="static/model_test.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Sample of nine predictions from test set
</figcaption>
</figure>
</div>
<p>To get a better measure of the success and accuracy of our model, we predicted the prices of all of our test data and then calculated the number of correct predictions at increasing margins (from $1 to $20).</p>
</section>
</section>
<section id="results" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="results"><span class="header-section-number">3</span> Results</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>Our model performed very well considering the limited dataset we had. 18% of test data predictions were within $1.00 of the actual price; within $3.00, 50% of predictions were accurate; and 83% of predictions were within $8.00 of actual price. Considering price variations on menus at different times of day (lunch vs.&nbsp;dinner menus), at different locations, varying image quality and type, and restaurant service charges and fees, we decided that being within $3–5 of actual price is decently accurate (see <a href="#tbl-accuracy" class="quarto-xref">Table&nbsp;1</a>, <a href="#fig-accuracy" class="quarto-xref">Figure&nbsp;4</a> for full results).</p>
<div id="fig-accuracy" class="lightbox quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="static/model_accuracy.png" class="lightbox" data-glightbox="description: .lightbox-desc-3" data-gallery="quarto-lightbox-gallery-3"><img src="static/model_accuracy.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Model accuracy at varying margins
</figcaption>
</figure>
</div>
</div><div class="column" style="width:5%;">
<!-- empty column to create gap -->
</div><div class="column" style="width:30%;">
<div id="tbl-accuracy" class="striped hover quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Model accuracy on training data at $1–$20 margins
</figcaption>
<div aria-describedby="tbl-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover table">
<thead>
<tr class="header">
<th>Margin</th>
<th style="text-align: right;">% Accurate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>$1.00</td>
<td style="text-align: right;">18.02%</td>
</tr>
<tr class="even">
<td>$3.00</td>
<td style="text-align: right;">49.70%</td>
</tr>
<tr class="odd">
<td>$2.00</td>
<td style="text-align: right;">36.34%</td>
</tr>
<tr class="even">
<td>$4.00</td>
<td style="text-align: right;">60.66%</td>
</tr>
<tr class="odd">
<td>$5.00</td>
<td style="text-align: right;">67.87%</td>
</tr>
<tr class="even">
<td>$6.00</td>
<td style="text-align: right;">74.77%</td>
</tr>
<tr class="odd">
<td>$7.00</td>
<td style="text-align: right;">79.28%</td>
</tr>
<tr class="even">
<td>$8.00</td>
<td style="text-align: right;">83.03%</td>
</tr>
<tr class="odd">
<td>$9.00</td>
<td style="text-align: right;">85.44%</td>
</tr>
<tr class="even">
<td>$10.00</td>
<td style="text-align: right;">87.99%</td>
</tr>
<tr class="odd">
<td>$11.00</td>
<td style="text-align: right;">89.79%</td>
</tr>
<tr class="even">
<td>$12.00</td>
<td style="text-align: right;">91.29%</td>
</tr>
<tr class="odd">
<td>$13.00</td>
<td style="text-align: right;">92.19%</td>
</tr>
<tr class="even">
<td>$14.00</td>
<td style="text-align: right;">93.24%</td>
</tr>
<tr class="odd">
<td>$15.00</td>
<td style="text-align: right;">93.84%</td>
</tr>
<tr class="even">
<td>$16.00</td>
<td style="text-align: right;">94.44%</td>
</tr>
<tr class="odd">
<td>$17.00</td>
<td style="text-align: right;">94.89%</td>
</tr>
<tr class="even">
<td>$18.00</td>
<td style="text-align: right;">95.80%</td>
</tr>
<tr class="odd">
<td>$19.00</td>
<td style="text-align: right;">96.25%</td>
</tr>
<tr class="even">
<td>$20.00</td>
<td style="text-align: right;">96.70%</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
</section>
<section id="future-work" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="future-work"><span class="header-section-number">4</span> Future Work</h2>
<p>During the building of our project we identified four core areas for improvement that were not critical to the performance of our model, but if given the time to implement, would likely increase our overall performance and application of our model.</p>
<p>During our examination of the collected data, we noticed a number of items that were not food: sodas, alcoholic beverages, restaurant merchandise, and cetera. We attempted to clean our data of these items by implementing a simple price filter (only including menu items between $10 and $50), but given the volume of data we collected, many non-food items were still included. If we feed the menu item names (and descriptions) to an LLM to classify and filter non-food menu items out from our input to the training of our model, we believe we could improve our accuracy. (We similarly could have included this type of filter prior to predicting an uploaded image as our web app will attempt to predict the price of any uploaded image, food or not.)</p>
<p>Secondly, we would love to have collected more data, especially data from cities outside of Washington, D.C., as prices differ around the country. Including the city in addition to the photo as input to the model may improve accuracy, especially outside of the DMV.</p>
<p>Third, we noticed that some menus changed prices depending on the type of day; the same item may be on a lunch and dinner menu but priced differently on both. Therefore we would have liked to gather data from the same restaurant multiple times during the day to get the full range of their prices and include that data in our model. Then, similarly to location, the user could input which meal they are eating along with their photo in order to get the most accurate price prediction.</p>
<p>Finally, we discovered some inconsistencies with price predictions on details hard to make out from images. For example, the model can’t tell if your burger is wagyu or regular beef, which has a big impact on the price. We would hope to train the model not just on the image but also its associated description or ingredients list from its menu, and for the user to optionally include a description of the meal in order to get the most accurate price estimate.</p>
</section>
<section id="references" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="references"><span class="header-section-number">5</span> References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-han" class="csl-entry" role="listitem">
Han, Liang, Zhaozheng Yin, Zhurong Xia, Li Guo, Mingqian Tang, and Rong Jin. 2019. <span>“Vision-Based Price Suggestion for Online Second-Hand Items.”</span> In <em>Proceedings of the 27th ACM International Conference on Multimedia</em>, 1988–96. MM ’19. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3343031.3350936">https://doi.org/10.1145/3343031.3350936</a>.
</div>
<div id="ref-nordin" class="csl-entry" role="listitem">
Nordin, Md Jan, Ooi Wei Xin, and Norshakirah Aziz. 2019. <span>“Food Image Recognition for Price Calculation Using Convolutional Neural Network.”</span> In <em>Proceedings of the 2019 3rd International Conference on Digital Signal Processing</em>, 80–85. ICDSP ’19. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3316551.3316557">https://doi.org/10.1145/3316551.3316557</a>.
</div>
</div>
<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Figure&nbsp;2: Model diagram</span>
<span class="glightbox-desc lightbox-desc-2">Figure&nbsp;3: Sample of nine predictions from test set</span>
<span class="glightbox-desc lightbox-desc-3">Figure&nbsp;4: Model accuracy at varying margins</span>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"descPosition":"bottom","closeEffect":"zoom","loop":false,"openEffect":"zoom","selector":".lightbox"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="paper_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>